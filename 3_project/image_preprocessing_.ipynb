{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.stats import chi2\n",
    "from typing import Tuple, Dict, List\n",
    "import glob\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import utils as ut\n",
    "\n",
    "import spectral as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_images(\n",
    "        input_dir: str,\n",
    "        mask: np.ndarray,\n",
    "        homographies: Dict[str, List[List[float]]]\n",
    ") -> Tuple[Dict[str, Dict[str, Dict[str, np.ndarray]]], Dict[str, Dict[str, Dict[str, np.ndarray]]]]:\n",
    "    \"\"\"\n",
    "    Finds all .png files recursively in a given input directory. The images are loaded,\n",
    "    a mask is applied to filter unwanted regions of the images and the images get\n",
    "    warped based on the provided homographies.\n",
    "    With this dictionary structure it can be assured that the images of one\n",
    "    image set always go together.\n",
    "\n",
    "    Args:\n",
    "        input_dir: Input directory which contains .png images\n",
    "        mask: Filter to mask out unwanted regions of all images at the same position\n",
    "        homographies: Dictionary mapping the file name to the associated homography\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing 2 dictionaries for the original and warped images.\n",
    "        Each dictionary is structured as follows:\n",
    "            {Folder Name (e.g. \"valid-1-0\"): {File Set Number (e.g. 0): {File Name (e.g. 0-B01): Image as array}}}\n",
    "    \"\"\"\n",
    "    input_dir = os.path.abspath(input_dir)\n",
    "\n",
    "    sorted_files = sorted(glob.glob(\n",
    "        os.path.join(input_dir, '**', '*.png'),\n",
    "        recursive=True\n",
    "    ))\n",
    "\n",
    "    original_images = {}\n",
    "    warped_images = {}\n",
    "\n",
    "    for file in sorted_files:\n",
    "        folders, file_name = os.path.split(file)\n",
    "        file_name = file_name.split('.')[0]\n",
    "        folder_name = os.path.basename(folders)\n",
    "        file_set = file_name.split('-')[0]\n",
    "\n",
    "        if folder_name not in original_images and folder_name not in warped_images:\n",
    "            original_images[folder_name] = {}\n",
    "            warped_images[folder_name] = {}\n",
    "\n",
    "        if file_set not in original_images[folder_name] and file_set not in warped_images[folder_name]:\n",
    "            original_images[folder_name].update({file_set: {}})\n",
    "            warped_images[folder_name].update({file_set: {}})\n",
    "\n",
    "        img = cv2.imread(file)\n",
    "        w, h, _ = img.shape\n",
    "        img = cv2.bitwise_and(img,img,mask=mask) #apply the mask to remove the timestamp\n",
    "        original_images[folder_name][file_set].update({file_name: img}) #save the original\n",
    "\n",
    "        homography = np.array(homographies[file_name]) #get homography\n",
    "\n",
    "        warped_img = cv2.warpPerspective(img, homography, (w,h)) #warp the image using the given homography\n",
    "        warped_images[folder_name][file_set].update({file_name: warped_img})\n",
    "\n",
    "    return original_images, warped_images\n",
    "\n",
    "MASK = 'data/mask.png'\n",
    "IMAGE_FOLDER = 'data/validation/valid-1-0/'\n",
    "\n",
    "mask = cv2.imread(MASK,0)\n",
    "homographies = json.loads(open(IMAGE_FOLDER+'homographies.json','r').read())\n",
    "\n",
    "#images = []\n",
    "\n",
    "orig_images, warped_images = read_images(IMAGE_FOLDER, mask, homographies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = 'data/mask.png'\n",
    "IMAGE_FOLDER = 'data/validation/valid-1-0/'\n",
    "\n",
    "mask = cv2.imread(MASK,0)\n",
    "homographies = json.loads(open(IMAGE_FOLDER+'homographies.json','r').read())\n",
    "\n",
    "#images = []\n",
    "\n",
    "orig_images = []\n",
    "warped_images = []\n",
    "\n",
    "for root, dirs, files in os.walk(IMAGE_FOLDER):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            img = cv2.imread(os.path.join(root,file))\n",
    "            w,h,_ = img.shape\n",
    "            res = cv2.bitwise_and(img,img,mask=mask) #apply the mask to remove the timestamp\n",
    "            orig_images.append(res) #save the original\n",
    "\n",
    "            w,h,_ = img.shape\n",
    "            name = file.replace('.png','')\n",
    "            M = np.array(homographies[name]) #get homography\n",
    "\n",
    "            res = cv2.warpPerspective(res, M, (w,h)) #warp the image using the given homography\n",
    "            warped_images.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(images, figsize=None, resize_dim=(200, 200)):\n",
    "    if figsize: row, col = figsize\n",
    "    else: row, col = 1,1\n",
    "        \n",
    "    fig, axs = plt.subplots(row, col, figsize=figsize)\n",
    "    if row>1 or col>1: axs = axs.flatten()\n",
    "    else: axs = [axs]\n",
    "    fig.set_figwidth(20)\n",
    "    fig.set_figheight(15)\n",
    "    \n",
    "    for img, ax in zip(images, axs):\n",
    "        ax.imshow(cv2.resize(img, resize_dim), interpolation='nearest')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(np.array(warped_images), figsize=(7,10), resize_dim=(200,200))\n",
    "#display_images(np.array(warped_images), figsize=(7,10), resize_dim=(200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate(images: np.ndarray):\n",
    "\n",
    "    integrated_images = []\n",
    "    \"\"\"\n",
    "    This is going through all the sets of images,True\n",
    "    where images[0] represents 10 images in a numpy array\n",
    "    \"\"\"\n",
    "    for i in range(len(images)): \n",
    "        integral = np.zeros((images[0].shape[1:]), np.float64)\n",
    "        #divider = np.zeros((images[0].shape[1:]), np.float64)\n",
    "        \n",
    "        for j in range(len(images[i])):\n",
    "            integral += images[i][j]\n",
    "            #cc = color_check(images[i][j])\n",
    "            #integral += (images[i][j]*cc[:,:,np.newaxis])\n",
    "            #divider += cc[:,:,np.newaxis]\n",
    "\n",
    "        integral /= len(images[i]) #np.divide(integral, divider, out=np.zeros_like(integral), where=divider!=0)\n",
    "        integral=cv2.normalize(integral, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        integrated_images.append(integral)\n",
    "\n",
    "    return integrated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_check(image: np.ndarray):\n",
    "    height, width = image.shape[:2]\n",
    "    cc = np.zeros(image.shape, np.float64)\n",
    "    for y,x in zip(range(height),range(width)):\n",
    "        if all(image[x,y] != [0,0,0]):\n",
    "            cc[x,y]=[0,0,0]\n",
    "    return np.array(cc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image):\n",
    "\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _,thresh = cv2.threshold(grayscale,0,255,cv2.THRESH_OTSU)\n",
    "\n",
    "    bbox = cv2.boundingRect(thresh)\n",
    "    x,y,w,h = bbox\n",
    "    \n",
    "    return x,y,w,h\n",
    "    #plt.imshow(grayscale[y:y+h,x:x+w], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_images = integrate(np.array_split(warped_images,10))\n",
    "\n",
    "int_img = [integrated_images[0]]\n",
    "\n",
    "display_images(np.array(int_img), resize_dim=(800,800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxvals = []\n",
    "\n",
    "for img in integrated_images:\n",
    "    rxvals.append(sp.rx(img))\n",
    "\n",
    "nbands = integrated_images[0].shape[-1]\n",
    "P=chi2.ppf(0.99999, nbands)\n",
    "\n",
    "#v=plt.imshow(1*(rxvals[0]>P))\n",
    "v = plt.imshow(np.log(rxvals[0]))\n",
    "#print(rxvals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_img = orig_images[0]\n",
    "\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rxd(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implementation of the Reed-Xiaoli detector. Calculates a score for each pixel as the\n",
    "    Mahalanobis distance between the pixel and the background.\n",
    "\n",
    "    Args:\n",
    "        img: Image in the shape Height x Width x 3\n",
    "\n",
    "    Returns:\n",
    "        Numpy array with the Mahalanobis distance of each pixel with shape Height x Width of the input image\n",
    "    \"\"\"\n",
    "    h, w, c = img.shape\n",
    "\n",
    "    # Calculate Mean Vector\n",
    "    mean_vec = np.mean(img, axis=(0, 1))\n",
    "\n",
    "    # Calculate Covariance Matrix\n",
    "    img_tmp = img.copy()\n",
    "    img_tmp = img_tmp.astype('float32') - mean_vec\n",
    "    img_tmp = img_tmp.reshape(-1, 3)\n",
    "    cov_mat = (img_tmp.T @ img_tmp) / (img_tmp.shape[0] - 1)\n",
    "\n",
    "    # Initialize Result Matrix\n",
    "    D_rx = np.zeros((h,w))\n",
    "\n",
    "    # Calculate Mahalanobis distance\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            r = img[i,j]\n",
    "            r_normal = r - mean_vec\n",
    "            D_rx[i,j] = r_normal.T @ np.linalg.inv(cov_mat) @ r_normal\n",
    "\n",
    "    return D_rx\n",
    "\n",
    "\n",
    "test_rxd = rxd(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def anomaly_mask(rxd_arr: np.ndarray, conf_coef: float=0.999, verbose: bool=False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates a threshold for the values of the RX-detector in order to find\n",
    "    only the most extreme anomalies which have a higher RX-score than conf_coef %\n",
    "    of the values in the array. All values below this threshold are set to 0.\n",
    "    If verbose is True, then the cumulative probability density of the rxd_array is\n",
    "    printed alongside the returned mask.\n",
    "\n",
    "    Args:\n",
    "        rxd_arr: Output of the rxd function -> RX-Values of an image\n",
    "        conf_coef: Confidence coefficient to control the cutoff for actual anomalies\n",
    "        verbose: Control whether plots should be created or not\n",
    "\n",
    "    Returns:\n",
    "        Anomaly mask where all pixels except anomaly are set to 0\n",
    "    \"\"\"\n",
    "\n",
    "    rxd_sorted = np.sort(rxd_arr.flatten())\n",
    "    prob = 1. * np.arange(len(rxd_sorted)) / (len(rxd_sorted) - 1)\n",
    "\n",
    "    threshold_idx = np.argwhere(prob > conf_coef)[0][0]\n",
    "    threshold = rxd_sorted[threshold_idx]\n",
    "\n",
    "    mask = rxd_arr > threshold\n",
    "\n",
    "    rxd_arr[~mask] = 0\n",
    "\n",
    "    if verbose:\n",
    "        fig = plt.figure(figsize=(15,7))\n",
    "        ax1 = fig.add_subplot(121)\n",
    "        ax1.plot(rxd_sorted, prob)\n",
    "        ax1.title.set_text(\"CDF of RX-Values\")\n",
    "        ax1.set_xlabel(\"RX Value\")\n",
    "        ax1.set_ylabel(\"Cumulative Probability\")\n",
    "\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.imshow(rxd_arr)\n",
    "        ax2.title.set_text(\"Anomaly Mask\")\n",
    "\n",
    "    return rxd_arr\n",
    "\n",
    "rx_mask = anomaly_mask(test_rxd, 0.999, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(IMAGE_FOLDER, 'labels.json'), 'r') as label_file:\n",
    "    gtlabels = json.load(label_file)\n",
    "\n",
    "val_img = cv2.imread('data/validation/valid-1-0/3-B01.png')\n",
    "\n",
    "def add_bounding_boxes(\n",
    "        img: np.ndarray,\n",
    "        gtlabels: List[List[int]],\n",
    "        rgb_color: Tuple[int] = (0, 0, 255),\n",
    "        thickness: int = 5\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adds the given bounding boxes to an image. These bounding boxes are\n",
    "    only aligned for the center image!\n",
    "\n",
    "    Args:\n",
    "        img: Image to which bounding boxes should be added\n",
    "        gtlabels: Bounding boxes from a labels.json file\n",
    "        rgb_color: Tuple representing the RGB color of the box\n",
    "        thickness: Thickness of the box line\n",
    "\n",
    "    Returns:\n",
    "        Image with an overlayed bounding boxes\n",
    "    \"\"\"\n",
    "    for bb in gtlabels:\n",
    "        x, y, w, h = bb\n",
    "        img = cv2.rectangle(\n",
    "            img=img,\n",
    "            pt1=(x,y),\n",
    "            pt2=(x+w, y+h),\n",
    "            color=rgb_color,\n",
    "            thickness=thickness\n",
    "        )\n",
    "\n",
    "    return img\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(add_bounding_boxes(val_img, gtlabels))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a87a44dc2bd0a6582416aef7a63772e61f6c8c45285afa158dd28660b11132d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('cvlab2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}