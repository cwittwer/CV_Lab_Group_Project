{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Lab Project - JKU - 2021\n",
    "### Team B0\n",
    "  \n",
    "Team Members: Dominik Heindl, Philipp Eberstaller, Carson Wittwer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from time import time, gmtime, strftime\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spectral as sp\n",
    "from scipy.stats import chi2\n",
    "\n",
    "import torch\n",
    "from torchvision.io import write_video\n",
    "from torchvision.transforms import functional, ToTensor, Lambda, Compose\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import utils as ut\n",
    "\n",
    "from clahe import clahe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_homographies(input_dir: str):\n",
    "    \"\"\"\n",
    "    Finds all homographies.json files recursively in a given input directory.\n",
    "\n",
    "    Args:\n",
    "        input_dir: Input directory which contains .json files\n",
    "\n",
    "    Returns:\n",
    "        A dictionary mapping the folder names to dictionaries with the homographies\n",
    "        Each dictionary is structured as follows:\n",
    "            {Folder Name (e.g. \"valid-1-0\"): {File Name (e.g. 0-B01): List[homographies]}}}\n",
    "    \"\"\"\n",
    "    sorted_homographies = sorted(glob.glob(\n",
    "        os.path.join(input_dir, '**', '*ies.json'),\n",
    "        recursive=True\n",
    "    ))\n",
    "\n",
    "    homographies = {}\n",
    "\n",
    "    for file in sorted_homographies:\n",
    "        folders, file_name = os.path.split(file)\n",
    "        folder_name = os.path.basename(folders)\n",
    "\n",
    "        homographies[folder_name] = json.loads(open(file, 'r').read())\n",
    "\n",
    "    return homographies\n",
    "\n",
    "\n",
    "def read_images(\n",
    "        input_dir: str,\n",
    "        mask: np.ndarray,\n",
    "        integrated_only: bool = True\n",
    ") -> Tuple[Dict[str, Dict[str, Dict[str, np.ndarray]]], Dict[str, Dict[str, Dict[str, np.ndarray]]]]:\n",
    "    \"\"\"\n",
    "    Finds all .png files recursively in a given input directory. The images are loaded,\n",
    "    a mask is applied to filter unwanted regions of the images and the images get\n",
    "    warped based on the provided homographies.\n",
    "    With this dictionary structure it can be assured that the images of one\n",
    "    image set always go together.\n",
    "\n",
    "    Args:\n",
    "        input_dir: Input directory which contains .png images\n",
    "        mask: Filter to mask out unwanted regions of all images at the same position\n",
    "        integrated_only: Whether to load only the integrated\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing 2 dictionaries for the original and warped images.\n",
    "        Each dictionary is structured as follows:\n",
    "            {Folder Name (e.g. \"valid-1-0\"): {File Set Number (e.g. 0): {File Name (e.g. 0-B01): Image as array}}}\n",
    "    \"\"\"\n",
    "    input_dir = os.path.abspath(input_dir)\n",
    "\n",
    "    if integrated_only:\n",
    "        sorted_files = sorted(glob.glob(\n",
    "            os.path.join(input_dir, '**', '*-int_image.png'),\n",
    "            recursive=True\n",
    "        ))\n",
    "    else:\n",
    "        sorted_files = sorted(glob.glob(\n",
    "            os.path.join(input_dir, '**', '*.png'),\n",
    "            recursive=True\n",
    "        ))\n",
    "\n",
    "        homographies = load_homographies(input_dir)\n",
    "\n",
    "    original_images = {}\n",
    "    warped_images = {}\n",
    "    \n",
    "    for file in sorted_files:\n",
    "        \n",
    "        folders, file_name = os.path.split(file)\n",
    "        \n",
    "        if not integrated_only:\n",
    "            if any(x not in file_name for x in ('mask', 'int_image', 'mask_image')):\n",
    "                continue\n",
    "\n",
    "        file_name = file_name.split('.')[0]\n",
    "        folder_name = os.path.basename(folders)\n",
    "        file_set = file_name.split('-')[0]\n",
    "\n",
    "        if folder_name not in original_images and folder_name not in warped_images:\n",
    "                original_images[folder_name] = {}\n",
    "                warped_images[folder_name] = {}\n",
    "\n",
    "        if file_set not in original_images[folder_name] and file_set not in warped_images[folder_name]:\n",
    "            original_images[folder_name].update({file_set: {}})\n",
    "            warped_images[folder_name].update({file_set: {}})\n",
    "\n",
    "        img = cv2.imread(file)\n",
    "        \n",
    "        if not integrated_only:\n",
    "\n",
    "            if folder_name not in warped_images:\n",
    "                warped_images[folder_name] = {}\n",
    "\n",
    "            if file_set not  in warped_images[folder_name]:\n",
    "                warped_images[folder_name].update({file_set: {}})\n",
    "\n",
    "            w, h, _ = img.shape\n",
    "            img = cv2.bitwise_and(img,img,mask=mask) #apply the mask to remove the timestamp\n",
    "\n",
    "            homography = np.array(homographies[folder_name][file_name]) #get homography\n",
    "\n",
    "            warped_img = cv2.warpPerspective(img, homography, (w,h)) #warp the image using the given homography\n",
    "            warped_images[folder_name][file_set].update({file_name: warped_img})\n",
    "\n",
    "        original_images[folder_name][file_set].update({file_name: img}) #save the original\n",
    "\n",
    "    return original_images, warped_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(images, figsize=None, resize_dim=(200, 200)):\n",
    "    if figsize: row, col = figsize\n",
    "    else: row, col = 1,1\n",
    "        \n",
    "    fig, axs = plt.subplots(row, col, figsize=figsize)\n",
    "    if row>1 or col>1: axs = axs.flatten()\n",
    "    else: axs = [axs]\n",
    "    fig.set_figwidth(20)\n",
    "    fig.set_figheight(15)\n",
    "    \n",
    "    for img, ax in zip(images, axs):\n",
    "        ax.imshow(cv2.resize(img, resize_dim), interpolation='nearest')\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "def integrate(images: np.ndarray):\n",
    "\n",
    "    integrated_images = []\n",
    "    mask_images = []\n",
    "    background_images = []\n",
    "    \"\"\"\n",
    "    This is going through all the sets of images,True\n",
    "    where images[0] represents 10 images in a numpy array\n",
    "    \"\"\"\n",
    "    for i in range(len(images)): \n",
    "        integral = np.zeros((images[0].shape[1:]), np.float64)\n",
    "        mask = np.zeros((images[0].shape[1:]), np.float64)\n",
    "        mask = mask[:,:,0]\n",
    "        mask_ = np.copy(mask)\n",
    "\n",
    "        for j in range(len(images[i])):\n",
    "            integral += images[i][j]\n",
    "            \n",
    "            height, width, _ = images[i][j].shape\n",
    "            for x in range(height):\n",
    "                for y in range(width):\n",
    "                    if all(images[i][j][x,y] == [0,0,0]):\n",
    "                        mask[x,y] += 1\n",
    "        \n",
    "        x,y = mask.shape\n",
    "        for n in range(x):\n",
    "            for m in range(y):\n",
    "                if mask[n,m] == 0:\n",
    "                    mask_[n,m] = 1\n",
    "                else:\n",
    "                    mask_[n,m] = 0\n",
    "        \n",
    "        #cv2.cvtColor(np.float32(mask_),cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        mask_images.append(mask_)\n",
    "        integral /= len(images[i]) \n",
    "        integral=cv2.normalize(integral, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        integrated_images.append(integral)\n",
    "\n",
    "    return integrated_images , mask_images\n",
    "\n",
    "def color_check(image: np.ndarray):\n",
    "    height, width = image.shape[:2]\n",
    "    cc = np.zeros(image.shape, np.float64)\n",
    "    for y,x in zip(range(height),range(width)):\n",
    "        if all(image[x,y] != [0,0,0]):\n",
    "            cc[x,y]=[0,0,0]\n",
    "    return np.array(cc)\n",
    "\n",
    "def crop_image(image):\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _,thresh = cv2.threshold(grayscale,0,255,cv2.THRESH_OTSU)\n",
    "\n",
    "    bbox = cv2.boundingRect(thresh)\n",
    "    x,y,w,h = bbox\n",
    "    \n",
    "    return x,y,w,h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Anomaly Detection\n",
    "\n",
    "I think it is good if we use a proper base class for the anomaly detection, this should ensure a unified interface which can be used at any point in our pipeline. Basically any algorithm implementation / class should have the method `anomaly_mask` which should return a mask where outliers are marked with 1 and other pixels remain 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDetection(ABC):\n",
    "    def __init__(self, img: np.ndarray):\n",
    "        self.img = img\n",
    "\n",
    "    @abstractmethod\n",
    "    def anomaly_mask(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Takes whatever is necessary from the current object to generate an anomaly\n",
    "        mask. The mask has the same height and width as the input image, anomalies are\n",
    "        marked as 1, everything als with 0.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reed-Xiaoli Detector\n",
    "This anomaly detection algorithm is the baseline, which should not be used. Nevertheless it is good to have it implemented for comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ReedXiaoliAnomaly(AnomalyDetection):\n",
    "    def __init__(\n",
    "            self,\n",
    "            img: np.ndarray,\n",
    "            conf_coef: float = 0.999,\n",
    "            verbose: bool = False\n",
    "    ):\n",
    "        super().__init__(img)\n",
    "        self.conf_coef = conf_coef\n",
    "        self.verbose = verbose\n",
    "        self.D_rx = None\n",
    "        self.mask = None\n",
    "\n",
    "    def _rxd(self):\n",
    "        \"\"\"\n",
    "        Implementation of the Reed-Xiaoli detector. Calculates a score for each pixel as the\n",
    "        Mahalanobis distance between the pixel and the background.\n",
    "\n",
    "        Args:\n",
    "            img: Image in the shape Height x Width x 3\n",
    "\n",
    "        Returns:\n",
    "            Numpy array with the Mahalanobis distance of each pixel with shape Height x Width of the input image\n",
    "        \"\"\"\n",
    "        h, w, c = self.img.shape\n",
    "\n",
    "        # Calculate Mean Vector\n",
    "        mean_vec = np.mean(img, axis=(0, 1))\n",
    "\n",
    "        # Calculate Covariance Matrix\n",
    "        img_tmp = img.copy()\n",
    "        img_tmp = img_tmp.astype('float32') - mean_vec\n",
    "        img_tmp = img_tmp.reshape(-1, 3)\n",
    "        cov_mat = (img_tmp.T @ img_tmp) / (img_tmp.shape[0] - 1)\n",
    "\n",
    "        # Initialize Result Matrix\n",
    "        D_rx = np.zeros((h,w))\n",
    "\n",
    "        # Calculate Mahalanobis distance\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                r = img[i,j]\n",
    "                r_normal = r - mean_vec\n",
    "                D_rx[i,j] = r_normal.T @ np.linalg.inv(cov_mat) @ r_normal\n",
    "\n",
    "        return D_rx\n",
    "\n",
    "    def anomaly_mask(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculates a threshold for the values of the RX-detector in order to find\n",
    "        only the most extreme anomalies which have a higher RX-score than conf_coef %\n",
    "        of the values in the array. All values below this threshold are set to 0.\n",
    "        If verbose is True, then the cumulative probability density of the rxd_array is\n",
    "        printed alongside the returned mask.\n",
    "\n",
    "        Returns:\n",
    "            Anomaly mask where anomalies are 0, everything else is 0\n",
    "        \"\"\"\n",
    "        self.D_rx = self._rxd()\n",
    "        rxd_arr = self.D_rx.copy()\n",
    "        rxd_sorted = np.sort(rxd_arr.flatten())\n",
    "        prob = 1. * np.arange(len(rxd_sorted)) / (len(rxd_sorted) - 1)\n",
    "\n",
    "        threshold_idx = np.argwhere(prob > self.conf_coef)[0][0]\n",
    "        threshold = rxd_sorted[threshold_idx]\n",
    "\n",
    "        mask = np.where(rxd_arr > threshold, 1, 0)\n",
    "        # mask = rxd_arr > threshold\n",
    "        # rxd_arr[mask] = 1\n",
    "        # rxd_arr[~mask] = 0\n",
    "\n",
    "        self.mask = mask\n",
    "\n",
    "        if self.verbose:\n",
    "            fig = plt.figure(figsize=(15,7))\n",
    "            ax1 = fig.add_subplot(121)\n",
    "            ax1.plot(rxd_sorted, prob)\n",
    "            ax1.title.set_text(\"CDF of RX-Values\")\n",
    "            ax1.set_xlabel(\"RX Value\")\n",
    "            ax1.set_ylabel(\"Cumulative Probability\")\n",
    "\n",
    "            ax2 = fig.add_subplot(122)\n",
    "            ax2.imshow(rxd_arr)\n",
    "            ax2.title.set_text(\"Anomaly Mask\")\n",
    "\n",
    "        return self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Residual Approach\n",
    "\n",
    "Originally this should be an implementation from `Reducing Anomaly Detection in Images to Detection in Noise` by Davy et al. The implementation is heavily influenced from this [GitHub Repository](https://github.com/whynotw/reducing_anomaly_detection), however by pure chance I stumbled across the fact that a burred version of the residual image is already looking promising for detection outliers. <br>\n",
    "A disadvantage is that this algorithm takes ~1 min. per image to create the anomaly mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualAnomaly(AnomalyDetection):\n",
    "    def __init__(\n",
    "            self,\n",
    "            img: np.ndarray,\n",
    "            filter_size: int = 7,\n",
    "            stride: int = 3,\n",
    "            number_k: int = 5,\n",
    "            threshold_intensity: int = 9\n",
    "    ):\n",
    "        super().__init__(img)\n",
    "        if filter_size % 2 == 0:\n",
    "            print(\"size of filter %d should be odd number\" % filter_size)\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.k = number_k\n",
    "        self.threshold_intensity = threshold_intensity\n",
    "\n",
    "        self.image_origin = img\n",
    "        h, w, _ = img.shape\n",
    "\n",
    "        h_remain = (h - filter_size) % stride\n",
    "        w_remain = (w - filter_size) % stride\n",
    "        self.image_origin = self.image_origin[:h - h_remain, :w - w_remain, :]\n",
    "\n",
    "        self.h, self.w, _ = self.image_origin.shape\n",
    "        self.h_red = (self.h - self.filter_size) // self.stride + 1\n",
    "        self.w_red  = (self.w - self.filter_size) // self.stride + 1\n",
    "        self.dim_data = 3 * self.filter_size ** 2\n",
    "        self.img_acc = np.zeros((self.h, self.w, 3), dtype=np.float32)\n",
    "        self.pixel_count = np.zeros((self.h, self.w), dtype=np.uint8)\n",
    "\n",
    "        tmp_idx = np.arange(0, self.w_red * self.stride, self.stride, dtype=np.uint16)\n",
    "        self.x0_data = np.stack((tmp_idx, ) * self.h_red)\n",
    "        self.x1_data = self.x0_data+self.filter_size\n",
    "\n",
    "        tmp_idx = np.arange(0, self.h_red * self.stride, self.stride, dtype=np.uint16)\n",
    "        self.y0_data = np.stack((tmp_idx, ) * self.w_red).T\n",
    "        self.y1_data = self.y0_data+self.filter_size\n",
    "        self.knn = cv2.ml.KNearest_create()\n",
    "\n",
    "        self.mask = None\n",
    "\n",
    "    def _create_patches(self):\n",
    "        \"\"\"\n",
    "        Divides the given image into pathes with size filter_size x filter_size.\n",
    "        The filter is then moves forward for stride pixels. All patches are saved\n",
    "        in the data object for the knn algorithm.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.data_total  = np.empty((self.h_red, self.w_red, self.dim_data), dtype=np.uint8)\n",
    "        self.label_total = np.empty((self.h_red, self.w_red, 1), dtype=np.float32)\n",
    "\n",
    "        count = 0\n",
    "        for j in range(0, self.h_red):\n",
    "            for i in range(0, self.w_red):\n",
    "                x0 = i * self.stride\n",
    "                x1 = x0 + self.filter_size\n",
    "                y0 = j * self.stride\n",
    "                y1 = y0 + self.filter_size\n",
    "                self.data_total[j, i, :] = self.image_origin[y0:y1, x0:x1, :].reshape(-1)\n",
    "                self.label_total[j, i, 0] = count\n",
    "                count += 1\n",
    "\n",
    "    def _get_knn(self):\n",
    "        \"\"\"\n",
    "        Performs a knn algorithm on the previously calculated patches. This should\n",
    "        ensure that anomalies are true anomalies and not part of some bigger pattern\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        tmp_data = self.data_total.reshape((-1, self.dim_data)).astype(np.float32)\n",
    "\n",
    "        self.knn.train(\n",
    "            tmp_data,\n",
    "            cv2.ml.ROW_SAMPLE,\n",
    "            self.label_total.reshape(-1,1)\n",
    "        )\n",
    "\n",
    "        _, _, neighbours, distances = self.knn.findNearest(\n",
    "            tmp_data,\n",
    "            self.filter_size ** 2 + self.k\n",
    "        )\n",
    "        neighbours = neighbours.astype(np.int64)\n",
    "\n",
    "        return neighbours, distances\n",
    "\n",
    "    def _get_self_similar_estimate(self):\n",
    "        \"\"\"\n",
    "        Creates a \"self-similar\" version of each image patch which is later used\n",
    "        to create the residual image. The average values of the neighbour patches\n",
    "        are divided from the current patch.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        neighbours,distances = self._get_knn()\n",
    "\n",
    "        count = 0\n",
    "        for j in range(0, self.h_red):\n",
    "            for i in range(0, self.w_red):\n",
    "                patch = np.zeros((self.filter_size, self.filter_size, 3), dtype=np.float32)\n",
    "                x0 = self.stride * i\n",
    "                x1 = x0 + self.filter_size\n",
    "                y0 = self.stride * j\n",
    "                y1 = y0 + self.filter_size\n",
    "\n",
    "                partition = 1e-7\n",
    "                effective = -1\n",
    "\n",
    "                for k in range(len(neighbours)):\n",
    "                    n = neighbours[count][k]\n",
    "                    j_neighbour = n // self.w_red\n",
    "                    i_neighbour = n % self.w_red\n",
    "\n",
    "                    d = distances[count][k]\n",
    "\n",
    "                    x0_n = self.stride * i_neighbour\n",
    "                    x1_n = x0_n + self.filter_size\n",
    "                    y0_n = self.stride * j_neighbour\n",
    "                    y1_n = y0_n + self.filter_size\n",
    "\n",
    "                    if x0 > x1_n or x1 < x0_n or y0 > y1_n or y1 < y0_n:\n",
    "                        effective += 1\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    if effective == 0:\n",
    "                        d0 = d\n",
    "\n",
    "                    if effective >= self.k:\n",
    "                        break\n",
    "\n",
    "                    d -= d0\n",
    "                    factor = np.exp(-d/self.dim_data)\n",
    "\n",
    "                    if factor > 2**-8:\n",
    "                        patch += factor * (\n",
    "                            self.data_total[j_neighbour,i_neighbour,:]\n",
    "                                .reshape((self.filter_size, self.filter_size, 3))\n",
    "                        )\n",
    "                        partition += factor\n",
    "\n",
    "                self.img_acc[y0:y1, x0:x1, :] += patch / partition\n",
    "                self.pixel_count[y0:y1, x0:x1] += 1\n",
    "                count += 1\n",
    "\n",
    "        self.img_red = np.uint8(self.img_acc / np.stack((self.pixel_count,) * 3, axis=-1))\n",
    "\n",
    "    def anomaly_mask(self):\n",
    "        \"\"\"\n",
    "        Calculates the residual image -> original image - self similar version of it.\n",
    "        Then apply a GaussianBlus which removes weak outlier signals. The blurred image\n",
    "        is then filtered for the top outlier value > some threshold.\n",
    "\n",
    "        Returns:\n",
    "            Anomaly mask where anomalies are 0, everything else is 0\n",
    "        \"\"\"\n",
    "        self._create_patches()\n",
    "        self._get_self_similar_estimate()\n",
    "        tmp_residual = np.uint8(\n",
    "            np.sum(\n",
    "                np.abs(\n",
    "                    np.int16(self.img_red) - np.int16(self.image_origin)\n",
    "                ),\n",
    "                axis=-1\n",
    "            ) / 3\n",
    "        )\n",
    "\n",
    "        tmp_blurred = cv2.GaussianBlur(\n",
    "            tmp_residual,\n",
    "            (self.filter_size * 2 + 1,) * 2,\n",
    "            0\n",
    "        )\n",
    "\n",
    "        mask = np.where(tmp_blurred >= self.threshold_intensity, 1, 0)\n",
    "        self.mask = mask\n",
    "\n",
    "        return self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(IMAGE_FOLDER, 'labels.json'), 'r') as label_file:\n",
    "    gtlabels = json.load(label_file)\n",
    "\n",
    "val_img = cv2.imread('data/validation/valid-1-0/3-B01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Add given BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_bounding_boxes(\n",
    "        img: np.ndarray,\n",
    "        gtlabels: List[List[int]],\n",
    "        rgb_color: Tuple[int] = (0, 0, 255),\n",
    "        thickness: int = 5\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adds the given bounding boxes to an image. These bounding boxes are\n",
    "    only aligned for the center image!\n",
    "\n",
    "    Args:\n",
    "        img: Image to which bounding boxes should be added\n",
    "        gtlabels: Bounding boxes from a labels.json file\n",
    "        rgb_color: Tuple representing the RGB color of the box\n",
    "        thickness: Thickness of the box line\n",
    "\n",
    "    Returns:\n",
    "        Image with an overlayed bounding boxes\n",
    "    \"\"\"\n",
    "    for bb in gtlabels:\n",
    "        x, y, w, h = bb\n",
    "        img = cv2.rectangle(\n",
    "            img=img,\n",
    "            pt1=(x,y),\n",
    "            pt2=(x+w, y+h),\n",
    "            color=rgb_color,\n",
    "            thickness=thickness\n",
    "        )\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create new BB from anomaly mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_close(cnt1,cnt2, max_dist=30):\n",
    "    row1,row2 = cnt1.shape[0],cnt2.shape[0]\n",
    "    for i in range(row1):\n",
    "        for j in range(row2):\n",
    "            dist = np.linalg.norm(cnt1[i]-cnt2[j])\n",
    "            if abs(dist) < max_dist:\n",
    "                return True\n",
    "            elif i==row1-1 and j==row2-1:\n",
    "                return False\n",
    "\n",
    "def combine_contours(contours, min_area):\n",
    "    n = len(contours)\n",
    "    status = np.zeros((n,1))\n",
    "    \n",
    "    for i,cnt1 in enumerate(contours):\n",
    "        x = i    \n",
    "        if i != n-1:\n",
    "            for j,cnt2 in enumerate(contours[i+1:]):\n",
    "                x = x+1\n",
    "                dist = is_close(cnt1,cnt2)\n",
    "                if dist:\n",
    "                    val = min(status[i],status[x])\n",
    "                    status[x] = status[i] = val\n",
    "                else:\n",
    "                    if status[x]==status[i]:\n",
    "                        status[x] = i+1\n",
    "\n",
    "    unified = []\n",
    "    maximum = int(status.max())+1\n",
    "    for i in range(maximum):\n",
    "        pos = np.where(status==i)[0]\n",
    "        if pos.size != 0:\n",
    "            cont = np.vstack(contours[i] for i in pos)\n",
    "            hull = cv2.convexHull(cont)\n",
    "            if not cv2.contourArea(hull)< min_area:\n",
    "                unified.append(hull)\n",
    "                \n",
    "    return unified\n",
    "\n",
    "def area_filled(contour,mask):\n",
    "    \n",
    "    contour_area=np.zeros_like(mask)\n",
    "    cv2.drawContours(contour_area, [contour], -1, 1, -1)\n",
    "    \n",
    "    total=contour_area.sum()\n",
    "    mask_area=contour_area[mask.astype(bool)].sum()\n",
    "\n",
    "    return mask_area.sum()/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_boxes(image, mask, min_area=100, fill_threshold=0.3):\n",
    "    \n",
    "    contours = cv2.findContours(image.astype(np.uint8), mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    \n",
    "    if not len(contours):\n",
    "        detected_anomalies_bb = np.zeros((0,4))\n",
    "        \n",
    "        return detected_anomalies_bb, contours\n",
    "        \n",
    "    combined=combine_contours(contours, min_area)\n",
    "    combined = [c for c in combined if not area_filled(c,mask)<fill_threshold]\n",
    "    \n",
    "    if not len(combined):\n",
    "        detected_anomalies_bb = np.zeros((0,4))\n",
    "        return detected_anomalies_bb, combined\n",
    "    \n",
    "    detected_anomalies_bb = np.stack([cv2.boundingRect(c) for c in combined])\n",
    "    \n",
    "    return detected_anomalies_bb, combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lucas Kanade Optical Flow\n",
    "Doesn't work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    inRange checks whether the given cordinates line in the given image limits\n",
    "    cordinates, limits are tuples i.e., (X,Y) \n",
    "'''\n",
    "def inRange( cordinates, limits):\n",
    "\tx,y = cordinates\n",
    "\tX_Limit, Y_Limit = limits\n",
    "\treturn 0 <= x and x < X_Limit and 0 <= y and y < Y_Limit\n",
    "\n",
    "'''\n",
    "    opticalFlow calculates the displacements in X and Y directions i.e., (u,v)\n",
    "    given two consecutive images varying with time\n",
    "'''\n",
    "def optical_flow(old_frame, new_frame, window_size, min_quality=0.01):\n",
    "\n",
    "    max_corners = 10000\n",
    "    min_distance = 0.1\n",
    "    feature_list = cv2.goodFeaturesToTrack(old_frame, max_corners, min_quality, min_distance)\n",
    "\n",
    "    w = int(window_size/2)\n",
    "\n",
    "    old_frame = old_frame / 255\n",
    "    new_frame = new_frame / 255\n",
    "\n",
    "    #Convolve to get gradients w.r.to X, Y and T dimensions\n",
    "    kernel_x = np.array([[-1, 1], [-1, 1]])\n",
    "    kernel_y = np.array([[-1, -1], [1, 1]])\n",
    "    kernel_t = np.array([[1, 1], [1, 1]])\n",
    "\n",
    "    fx = cv2.filter2D(old_frame, -1, kernel_x)              #Gradient over X\n",
    "    fy = cv2.filter2D(old_frame, -1, kernel_y)              #Gradient over Y\n",
    "    ft = cv2.filter2D(new_frame, -1, kernel_t) - cv2.filter2D(old_frame, -1, kernel_t)  #Gradient over Time\n",
    "\n",
    "\n",
    "    u = np.zeros(old_frame.shape)\n",
    "    v = np.zeros(old_frame.shape)\n",
    "\n",
    "    for feature in feature_list:        #   for every corner\n",
    "            j, i = feature.ravel()\t\t#   get cordinates of the corners (i,j). They are stored in the order j, i\n",
    "            i, j = int(i), int(j)\t\t#   i,j are floats initially\n",
    "\n",
    "            I_x = fx[i-w:i+w+1, j-w:j+w+1].flatten()\n",
    "            I_y = fy[i-w:i+w+1, j-w:j+w+1].flatten()\n",
    "            I_t = ft[i-w:i+w+1, j-w:j+w+1].flatten()\n",
    "\n",
    "            b = np.reshape(I_t, (I_t.shape[0],1))\n",
    "            A = np.vstack((I_x, I_y)).T\n",
    "\n",
    "            U = np.matmul(np.linalg.pinv(A), b)     # Solving for (u,v) i.e., U\n",
    "\n",
    "            u[i,j] = U[0][0]\n",
    "            v[i,j] = U[1][0]\n",
    "\n",
    "    return (u,v)\n",
    "\n",
    "\n",
    "'''\n",
    "Draw the displacement vectors on the image, given (u,v) and save it to the output filepath provided\n",
    "'''\n",
    "def drawOnFrame(frame, U, V, output_file):\n",
    "\n",
    "    line_color = (0, 255, 0) #  Green\n",
    "\n",
    "    for i in range(frame.shape[0]):\n",
    "        for j in range(frame.shape[1]):\n",
    "            u, v = U[i][j], V[i][j]\n",
    "\n",
    "            if u and v:\n",
    "                frame = cv2.arrowedLine( frame, (i, j), (int(round(i+u)), int(round(j+v))),\n",
    "                                        (0, 255, 0),\n",
    "                                        thickness=1\n",
    "                                    )\n",
    "    cv2.imwrite(output_file, frame)\n",
    "\n",
    "\n",
    "'''\n",
    "Create a plot of the displacement vectors given (u,v) and plot the two images and displacement in a row.\n",
    "Save the plot to given output filepath\n",
    "'''\n",
    "def drawSeperately(old_frame, new_frame, U, V):\n",
    "\n",
    "    displacement = np.ones_like(new_frame)\n",
    "    displacement.fill(255.)             #Fill the displacement plot with White background\n",
    "    line_color =  (0, 0, 0)\n",
    "    # draw the displacement vectors\n",
    "    for i in range(new_frame.shape[0]):\n",
    "        for j in range(new_frame.shape[1]):\n",
    "\n",
    "            start_pixel = (i,j)\n",
    "            end_pixel = ( int(i+U[i][j]), int(j+V[i][j]) )\n",
    "\n",
    "            #check if there is displacement for the corner and endpoint is in range\n",
    "            if U[i][j] and V[i][j] and inRange( end_pixel, old_frame.shape ):     \n",
    "                displacement = cv2.arrowedLine( displacement, start_pixel, end_pixel, line_color, thickness =2)\n",
    "\n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    ax1 = fig.add_subplot(131)\n",
    "    ax1.imshow(old_frame)\n",
    "    ax1.title.set_text(\"First Image\")\n",
    "\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax2.imshow(new_frame)\n",
    "    ax2.title.set_text(\"Second Image\")\n",
    "\n",
    "    ax3 = fig.add_subplot(133)\n",
    "    ax3.imshow(displacement)\n",
    "    ax3.title.set_text(\"Displacements\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Locally \n",
    "\n",
    "Working on using the temporal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = 'data/mask.png'\n",
    "IMAGE_FOLDER = 'data/validation'\n",
    "\n",
    "mask = cv2.imread(MASK,0)\n",
    "\n",
    "orig_images_, warped_images_ = read_images(IMAGE_FOLDER, mask,integrated_only=False)\n",
    "\n",
    "img_lists = {}\n",
    "\n",
    "for img_set, time_step_dict in warped_images_.items():\n",
    "    img_lists[img_set] = []\n",
    "    for time_step, n_camera_dict in time_step_dict.items():\n",
    "        images = []\n",
    "        for cam, img in n_camera_dict.items():\n",
    "            images.append(img)\n",
    "        img_lists[img_set].append(np.array(images))\n",
    "\n",
    "\n",
    "for folder, list in img_lists.items():\n",
    "    int_images, mask_images = integrate(list)\n",
    "    display_images(int_images, figsize=(7,1), resize_dim=(200,200))\n",
    "    display_images(mask_images, figsize=(7,1), resize_dim=(200,200))\n",
    "    if True: exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background(images):\n",
    "    return np.median(images, axis=0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = 'data/mask.png'\n",
    "IMAGE_FOLDER = 'data_combined/validation/valid-1-0/'\n",
    "BB_LABELS_FOLDER = 'data/validation/valid-1-0/'\n",
    "\n",
    "mask = cv2.imread(MASK,0)\n",
    "#homographies = json.loads(open(IMAGE_FOLDER+'homographies.json','r').read())\n",
    "\n",
    "integrated_images = []\n",
    "mask_images = []\n",
    "anomaly_masks = []\n",
    "\n",
    "for root, dirs, files in os.walk(IMAGE_FOLDER):\n",
    "    for file in files:\n",
    "        if 'int_image' in file:\n",
    "            integrated_images.append(cv2.imread(os.path.join(root,file)))\n",
    "        elif 'mask_image' in file:\n",
    "            mask_images.append(cv2.imread(os.path.join(root,file)))\n",
    "        elif 'anomaly_mask' in file:\n",
    "            anomaly_masks.append(cv2.imread(os.path.join(root,file)))\n",
    "\n",
    "#display_images(np.array(integrated_images), figsize=(1,7), resize_dim=(200,200))\n",
    "#display_images(np.array(mask_images), figsize=(1,7), resize_dim=(200,200))\n",
    "#display_images(np.array(anomaly_masks), figsize=(1,7), resize_dim=(200,200))\n",
    "\n",
    "with open(os.path.join(BB_LABELS_FOLDER, 'labels.json'), 'r') as label_file:\n",
    "    gtlabels = json.load(label_file)\n",
    "\n",
    "with_valid_labels = []\n",
    "with_our_labels = []\n",
    "\"\"\"\n",
    "for i in range(len(integrated_images)):\n",
    "    with_valid_bbs = add_bounding_boxes(integrated_images[i],gtlabels)\n",
    "    with_valid_labels.append(with_valid_bbs)\n",
    "\n",
    "    our_bbs, thing = get_bounding_boxes(cv2.cvtColor(anomaly_masks[i],cv2.COLOR_BGR2GRAY),mask_images[i])\n",
    "    with_our_bbs = add_bounding_boxes(integrated_images[i],our_bbs.tolist(),rgb_color=(255,0,0))\n",
    "    with_our_labels.append(with_our_bbs)\n",
    "\n",
    "    #fig = plt.figure(figsize=(15,7))\n",
    "    #ax1 = fig.add_subplot(121)\n",
    "    #ax1.imshow(with_valid_bbs)\n",
    "    #ax1.title.set_text(\"Integrated Image BBs\")\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(integrated_images)-1):\n",
    "    im1 = cv2.cvtColor(integrated_images[i], cv2.COLOR_BGR2GRAY)\n",
    "    im2 = cv2.cvtColor(integrated_images[i+1], cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorizer = ToTensor()\n",
    "\n",
    "brightness_factor = 0.3\n",
    "contrast_factor = 4\n",
    "bri_cont_transform = Compose([\n",
    "    Lambda(lambda x: functional.adjust_brightness(x, brightness_factor)),\n",
    "    Lambda(lambda x: functional.adjust_contrast(x, contrast_factor))])\n",
    "\n",
    "# bri_cont_transform = ColorJitter(brightness=0.4, contrast=3)\n",
    "inverter_transform = Lambda(lambda x: functional.invert(x))\n",
    "\n",
    "ims = integrated_images.copy()\n",
    "\n",
    "inv = []\n",
    "\n",
    "for i in range(len(ims)):\n",
    "    ims[i] = tensorizer(ims[i])\n",
    "    bri_cont = bri_cont_transform(ims[i])\n",
    "    inverted = inverter_transform(bri_cont)\n",
    "    temp=inverted.permute(1, 2, 0).numpy()\n",
    "    inv.append(temp)\n",
    "\n",
    "display_images(inv, figsize=(1,7), resize_dim=(200,200))\n",
    "\n",
    "new_warps = []\n",
    "for j in range(len(inv)):\n",
    "    new_warps.append(cv2.cvtColor(inv[j], cv2.COLOR_BGR2GRAY))\n",
    "ims = np.vstack([im.reshape(1,im.shape[0] * im.shape[1]) for im in new_warps])\n",
    "# Compute the median column by column and reshape to the original shape:\n",
    "back_img = np.median(ims, axis=0).reshape(1024,1024)\n",
    "\n",
    "#inv.append(cv2.cvtColor(back_img,cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "#display_images(inv, figsize=(1,8), resize_dim=(200,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save Integrated Images, Anomaly Masks, etc.\n",
    "\n",
    "Run the following section only if you have a lot of time :^)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MASK = 'data/mask.png'\n",
    "IMAGE_FOLDER = 'data_combined/validation/'\n",
    "\n",
    "mask = cv2.imread(MASK,0)\n",
    "\n",
    "orig_images_, warped_images_ = read_images(IMAGE_FOLDER, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def integrate_and_save(warped_images: Dict[str, Dict[str, Dict[str, np.ndarray]]], target_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Takes the loaded and warped images, integrates the different camera views and saves the\n",
    "    integrated images in the provided directory.\n",
    "    Folder structure already has to be present!\n",
    "\n",
    "    Args:\n",
    "        warped_images: Warped images from the read_images function.\n",
    "        target_dir: Directory where the integrated images + integration mask should be saved\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    img_lists = {}\n",
    "\n",
    "    for img_set, time_step_dict in warped_images.items():\n",
    "        img_lists[img_set] = []\n",
    "        for time_step, n_camera_dict in time_step_dict.items():\n",
    "            images = []\n",
    "            for cam, img in n_camera_dict.items():\n",
    "                images.append(img)\n",
    "            img_lists[img_set].append(np.array(images))\n",
    "\n",
    "\n",
    "    for folder, list in img_lists.items():\n",
    "        if len(os.listdir(os.path.join(target_dir, folder))) > 0:\n",
    "            continue\n",
    "        start = time()\n",
    "        print(folder)\n",
    "        int_images, mask_images = integrate(list)\n",
    "        for i, (int, mas) in enumerate(zip(int_images, mask_images)):\n",
    "            cv2.imwrite(os.path.join(target_dir, folder, f'{i}-int_image.png'), int)\n",
    "            cv2.imwrite(os.path.join(target_dir, \"train\", folder, f'{i}-mask_image.png'), mas * 255)\n",
    "        print(f\"Time it took to integrate images from {folder}: {strftime('%H:%M:%S', gmtime(time()-start))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for folder, time_step_dict in orig_images_.items():\n",
    "    for time_step, img_dict in time_step_dict.items():\n",
    "        for _, img in img_dict.items():\n",
    "            start = time()\n",
    "            reducing = ResidualAnomaly(img=img)\n",
    "            red_mask = reducing.anomaly_mask()\n",
    "            cv2.imwrite(os.path.join(\"data_combined\", \"validation\", folder, f'{time_step}-anomaly_mask.png'), red_mask * 255)\n",
    "            print(f\"It took {strftime('%H:%M:%S', gmtime(time()-start))}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "309880611dc10c2c77b6215493853e20d809801fc96e4f9990c708260a42a5fe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('cv_project': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
